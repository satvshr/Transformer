{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":502516,"sourceType":"datasetVersion","datasetId":236282},{"sourceId":8147125,"sourceType":"datasetVersion","datasetId":4817926}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom nltk.tokenize import word_tokenize\nimport torch\nimport math\nimport re\nimport torch.nn as nn\nfrom torch.nn.utils.rnn import pad_sequence\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader, random_split\nimport numpy as np\nfrom tokenizers import ByteLevelBPETokenizer\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport nltk\nimport sentencepiece as spm\nnltk.download('punkt')","metadata":{"id":"7e893663-462c-4e19-98f0-2611f454ccf7","outputId":"96f88eb4-3db5-4384-94ad-74718a1b50fb","execution":{"iopub.status.busy":"2024-05-14T19:35:12.333588Z","iopub.execute_input":"2024-05-14T19:35:12.333953Z","iopub.status.idle":"2024-05-14T19:35:21.101823Z","shell.execute_reply.started":"2024-05-14T19:35:12.333924Z","shell.execute_reply":"2024-05-14T19:35:21.100569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!CUDA_LAUNCH_BLOCKING=1","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:35:21.104042Z","iopub.execute_input":"2024-05-14T19:35:21.104538Z","iopub.status.idle":"2024-05-14T19:35:22.215854Z","shell.execute_reply.started":"2024-05-14T19:35:21.104508Z","shell.execute_reply":"2024-05-14T19:35:22.214461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/poetry/poetry.csv\")","metadata":{"id":"46a99932-f65a-4ffd-981b-4eb2c1c32775","execution":{"iopub.status.busy":"2024-05-14T19:40:27.135986Z","iopub.execute_input":"2024-05-14T19:40:27.136673Z","iopub.status.idle":"2024-05-14T19:40:27.505667Z","shell.execute_reply.started":"2024-05-14T19:40:27.136640Z","shell.execute_reply":"2024-05-14T19:40:27.504087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.iloc[:len(df)]","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:40:27.508254Z","iopub.execute_input":"2024-05-14T19:40:27.508692Z","iopub.status.idle":"2024-05-14T19:40:27.513920Z","shell.execute_reply.started":"2024-05-14T19:40:27.508662Z","shell.execute_reply":"2024-05-14T19:40:27.512919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_colwidth', None)\ndf.tail()","metadata":{"id":"259e65ac-45c6-452d-b220-6f9e3f605093","outputId":"1d03b069-37f4-4e1d-9199-71d98240230c","execution":{"iopub.status.busy":"2024-05-14T19:40:27.555043Z","iopub.execute_input":"2024-05-14T19:40:27.555722Z","iopub.status.idle":"2024-05-14T19:40:27.569526Z","shell.execute_reply.started":"2024-05-14T19:40:27.555689Z","shell.execute_reply":"2024-05-14T19:40:27.568284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"id":"68c8a2b5-553f-494e-bed7-b87dda4a31a0","outputId":"f585a655-b3bb-47bb-cd1a-b220d06c67a9","execution":{"iopub.status.busy":"2024-05-14T19:40:27.740004Z","iopub.execute_input":"2024-05-14T19:40:27.740730Z","iopub.status.idle":"2024-05-14T19:40:27.756760Z","shell.execute_reply.started":"2024-05-14T19:40:27.740696Z","shell.execute_reply":"2024-05-14T19:40:27.755701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(['Unnamed: 0', 'Tags', 'Poet', 'Title'], axis=1)","metadata":{"id":"bfb30a34-a0f3-4202-b652-931b29a215a1","execution":{"iopub.status.busy":"2024-05-14T19:40:27.964696Z","iopub.execute_input":"2024-05-14T19:40:27.965127Z","iopub.status.idle":"2024-05-14T19:40:27.971673Z","shell.execute_reply.started":"2024-05-14T19:40:27.965095Z","shell.execute_reply":"2024-05-14T19:40:27.970470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df['Title'] = df['Title'].str.replace('\\r', '')\ndf['Poem'] = df['Poem'].str.replace('\\r', '')\n# df['Title'] = df['Title'].str.replace('\\n', '')\ndf['Poem'] = df['Poem'].str.strip('\\n')","metadata":{"id":"744c8e4b-7444-4c88-bceb-d1986680a5da","execution":{"iopub.status.busy":"2024-05-14T19:40:28.153779Z","iopub.execute_input":"2024-05-14T19:40:28.154213Z","iopub.status.idle":"2024-05-14T19:40:28.253124Z","shell.execute_reply.started":"2024-05-14T19:40:28.154176Z","shell.execute_reply":"2024-05-14T19:40:28.251538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail()","metadata":{"id":"XHKDr0NhuaQU","outputId":"b58474e3-1194-4563-e6c3-80a0aca43ee4","execution":{"iopub.status.busy":"2024-05-14T19:40:28.459008Z","iopub.execute_input":"2024-05-14T19:40:28.459457Z","iopub.status.idle":"2024-05-14T19:40:28.470970Z","shell.execute_reply.started":"2024-05-14T19:40:28.459425Z","shell.execute_reply":"2024-05-14T19:40:28.469236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lower case everything\n# df['Title'] = df['Title'].str.lower()\ndf['Poem'] = df['Poem'].str.lower()\n\n# Remove apostrophes and join the parts\n# df['Title'] = df['Title'].str.replace(\"'\", \"\", regex=False).str.replace(\"’\", \"\", regex=False)\ndf['Poem'] = df['Poem'].str.replace(\"'\", \"\", regex=False).str.replace(\"’\", \"\", regex=False)","metadata":{"id":"147cacee-0272-4883-a8b0-5e9f9cc42621","execution":{"iopub.status.busy":"2024-05-14T19:40:30.044104Z","iopub.execute_input":"2024-05-14T19:40:30.044721Z","iopub.status.idle":"2024-05-14T19:40:30.374198Z","shell.execute_reply.started":"2024-05-14T19:40:30.044689Z","shell.execute_reply":"2024-05-14T19:40:30.372903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Uncomment only when including encoder, until then let it be commented off\n# Filter out rows where both 'Title' and 'Poem' have no alphabetic characters\n\n# df = df[df.apply(lambda x: any(c.isalpha() for c in x['Title']) and\n#                             any(c.isalpha() for c in x['Poem']), axis=1)]\n\n# Filter out rows with no value (its not NaN its '' in this dataset)\ndf = df[df.apply(lambda x: any(c.isalpha() for c in x['Poem']), axis=1)]","metadata":{"id":"d53c2016-cbe5-4bcf-9a11-94f7abf27a6a","execution":{"iopub.status.busy":"2024-05-14T19:40:31.327790Z","iopub.execute_input":"2024-05-14T19:40:31.328221Z","iopub.status.idle":"2024-05-14T19:40:31.519348Z","shell.execute_reply.started":"2024-05-14T19:40:31.328189Z","shell.execute_reply":"2024-05-14T19:40:31.518008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make newline a special token\n# df['Title'] = 'START ' + df['Title'] + ' END'","metadata":{"id":"54d2c668-0a97-4e00-8976-f5260fb83bd7","outputId":"de90cac7-0b17-45ec-d9ae-46c21a88a93d","execution":{"iopub.status.busy":"2024-05-14T19:40:31.895207Z","iopub.execute_input":"2024-05-14T19:40:31.895819Z","iopub.status.idle":"2024-05-14T19:40:31.900408Z","shell.execute_reply.started":"2024-05-14T19:40:31.895788Z","shell.execute_reply":"2024-05-14T19:40:31.899115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_numeric_tokens(text):\n    tokens = word_tokenize(text)\n    # Filter tokens to exclude any that contain digits\n    filtered_tokens = [token for token in tokens if not re.search(r'\\d', token)]\n    processed_text = ' '.join(filtered_tokens)\n    return processed_text\n\ndf['Poem'] = df['Poem'].apply(remove_numeric_tokens)\ndf['Poem'] = '<s> ' + df['Poem'] + ' </s>'\ndf['Poem'] = df['Poem'].apply(lambda x: re.sub(r'\\n', ' <n> ', x))","metadata":{"id":"255a982a-7b39-49eb-814f-c56e15fc6b44","execution":{"iopub.status.busy":"2024-05-14T19:40:32.689146Z","iopub.execute_input":"2024-05-14T19:40:32.689759Z","iopub.status.idle":"2024-05-14T19:41:29.518742Z","shell.execute_reply.started":"2024-05-14T19:40:32.689729Z","shell.execute_reply":"2024-05-14T19:41:29.517245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail()","metadata":{"id":"HuEV8lK0uaQV","outputId":"a5c549af-cf15-408e-c308-eb9da816291a","execution":{"iopub.status.busy":"2024-05-14T19:41:29.521351Z","iopub.execute_input":"2024-05-14T19:41:29.521713Z","iopub.status.idle":"2024-05-14T19:41:29.535583Z","shell.execute_reply.started":"2024-05-14T19:41:29.521685Z","shell.execute_reply":"2024-05-14T19:41:29.534704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"id":"b6047bbd-4793-4e2f-8253-475883f55e9d","outputId":"3de94969-859f-4fa8-c0df-b7ca0c8b68c6","execution":{"iopub.status.busy":"2024-05-14T19:41:29.537157Z","iopub.execute_input":"2024-05-14T19:41:29.538170Z","iopub.status.idle":"2024-05-14T19:41:29.557077Z","shell.execute_reply.started":"2024-05-14T19:41:29.538136Z","shell.execute_reply":"2024-05-14T19:41:29.555511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.size","metadata":{"id":"9e54db8f-fd00-4736-972c-95dbfb990694","outputId":"705122bb-14e2-4c4d-8ff3-2c1787f0206e","execution":{"iopub.status.busy":"2024-05-14T19:41:29.560140Z","iopub.execute_input":"2024-05-14T19:41:29.560787Z","iopub.status.idle":"2024-05-14T19:41:29.574023Z","shell.execute_reply.started":"2024-05-14T19:41:29.560753Z","shell.execute_reply":"2024-05-14T19:41:29.572552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from tokenizers import SentencePieceBPETokenizer\n# from transformers import PreTrainedTokenizerFast\n\n# # Initialize and train SentencePieceBPETokenizer\n# spm.SentencePieceTrainer.train(\n#     input=poem_file,\n#     vocab_size=32000,\n#     bos_id=0,\n#     pad_id=1,  # Specify the padding token ID here\n#     eos_id=2,\n#     user_defined_symbols=special_tokens\n# )\n\n# # Define special tokens\n# special_tokens = [\"<s>\", \"</s>\", \"<pad>\"]\n\n# # Initialize PreTrainedTokenizerFast with SentencePieceBPETokenizer\n# tokenizer = PreTrainedTokenizerFast(\n#     tokenizer_object=spm,   \n#     special_tokens=special_tokens\n# )\n\n# tokenizer.bos_token = \"<s>\"\n# tokenizer.bos_token_id = tk_tokenizer.token_to_id(\"<s>\")\n# tokenizer.pad_token = \"<pad>\"\n# tokenizer.pad_token_id = tk_tokenizer.token_to_id(\"<pad>\")\n# tokenizer.eos_token = \"</s>\"\n# tokenizer.eos_token_id = tk_tokenizer.token_to_id(\"</s>\")\n# tokenizer.unk_token = \"<unk>\"\n\n# # Sentence to IDs\n# sentence = \"</s>\"\n# ids = tokenizer.encode(sentence)\n# print(\"IDs:\", ids)\n# print(tokenizer.decode(ids))","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:36:19.723714Z","iopub.execute_input":"2024-05-14T19:36:19.724143Z","iopub.status.idle":"2024-05-14T19:36:19.735376Z","shell.execute_reply.started":"2024-05-14T19:36:19.724112Z","shell.execute_reply":"2024-05-14T19:36:19.734053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving poems to a file (required for tokenizer training)\npoem_file = \"poems.txt\"\nwith open(poem_file, \"w\", encoding='utf-8') as file: \n    file.write('\\n'.join(df['Poem'])) \n\n# Train the SentencePiece tokenizer on the poems\nspm.SentencePieceTrainer.train(input=poem_file, model_prefix='poetry_model', vocab_size=32000, user_defined_symbols='<s>,</s>,<pad>,<n>')\n\n# Load the trained SentencePiece model\nsp = spm.SentencePieceProcessor()\nsp.load(\"poetry_model.model\")","metadata":{"id":"8568E4YRuaQV","execution":{"iopub.status.busy":"2024-05-14T19:44:59.395508Z","iopub.execute_input":"2024-05-14T19:44:59.395947Z","iopub.status.idle":"2024-05-14T19:45:19.297848Z","shell.execute_reply.started":"2024-05-14T19:44:59.395916Z","shell.execute_reply":"2024-05-14T19:45:19.296740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming you've loaded the trained SentencePiece model as 'sp'\n\n# Tokenize a sentence\nsentence = \"my dog is happy\"\nencoded_tokens = sp.EncodeAsIds(sentence)  # Use sp.EncodeAsIds for SentencePiece\n\nprint(\"Encoded tokens:\", encoded_tokens)\n\n# Decode the tokens back into words\ndecoded_sentence = sp.DecodeIds(encoded_tokens)  # Use sp.DecodeIds for SentencePiece\n\nprint(\"Decoded sentence:\", decoded_sentence)\n\n# Get the padding token ID\npad_token = sp.piece_to_id(\"<pad>\")  # Use sp.piece_to_id for SentencePiece\n\nprint(\"Padding Token ID:\", pad_token)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:36:20.460749Z","iopub.status.idle":"2024-05-14T19:36:20.461230Z","shell.execute_reply.started":"2024-05-14T19:36:20.461000Z","shell.execute_reply":"2024-05-14T19:36:20.461034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the range of IDs\nvocab_size = sp.get_piece_size()\nid_range = range(vocab_size)\nprint(\"Range of IDs:\", id_range)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:36:20.462700Z","iopub.status.idle":"2024-05-14T19:36:20.463139Z","shell.execute_reply.started":"2024-05-14T19:36:20.462926Z","shell.execute_reply":"2024-05-14T19:36:20.462943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_size = sp.get_piece_size()  # Number of unique words in the vocabulary\nembedding_dim = 256\nbatch_size = 32 # Increase batch size if resources allow as it bring stabilization, 1 is very noisy\nlearning_rate = 0.001 # changed lr because maybe the embedding dim is too low and lr is too high so gradient is just bouncing around and not learning much\nheads = 4\nepochs = 400\nseq_len = 300\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"0cb421f7-9dac-4651-a2cb-9167ffad6ab4","execution":{"iopub.status.busy":"2024-05-14T19:36:20.465190Z","iopub.status.idle":"2024-05-14T19:36:20.466139Z","shell.execute_reply.started":"2024-05-14T19:36:20.465821Z","shell.execute_reply":"2024-05-14T19:36:20.465844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(poem_file, \"r\", encoding='utf-8') as file: \n    f = file.read()\n    \ndata = torch.tensor(sp.encode_as_ids(f))","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:36:20.467857Z","iopub.status.idle":"2024-05-14T19:36:20.468913Z","shell.execute_reply.started":"2024-05-14T19:36:20.468672Z","shell.execute_reply":"2024-05-14T19:36:20.468694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessing(data, seq_len, pad_token):\n    input_tensor = []\n    target_tensor = []\n    i = 0\n\n    while i < len(data):\n        input_tensor.append(torch.tensor(data[i:i+seq_len]))\n        target_tensor.append(torch.tensor(data[i+1:i+seq_len+1]))\n        i += seq_len\n    \n    input_tensor = torch.nn.utils.rnn.pad_sequence(input_tensor, padding_value=pad_token, batch_first=True)\n    target_tensor = torch.nn.utils.rnn.pad_sequence(target_tensor, padding_value=pad_token, batch_first=True)\n    \n    return input_tensor, target_tensor\n\ninput_tensor, target_tensor = preprocessing(data, seq_len, pad_token)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:36:20.470330Z","iopub.status.idle":"2024-05-14T19:36:20.470741Z","shell.execute_reply.started":"2024-05-14T19:36:20.470547Z","shell.execute_reply":"2024-05-14T19:36:20.470563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_tensor.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:36:20.472749Z","iopub.status.idle":"2024-05-14T19:36:20.473412Z","shell.execute_reply.started":"2024-05-14T19:36:20.473200Z","shell.execute_reply":"2024-05-14T19:36:20.473227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_tensor.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:36:20.474542Z","iopub.status.idle":"2024-05-14T19:36:20.475165Z","shell.execute_reply.started":"2024-05-14T19:36:20.474953Z","shell.execute_reply":"2024-05-14T19:36:20.474970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_tensor[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:36:20.476235Z","iopub.status.idle":"2024-05-14T19:36:20.477026Z","shell.execute_reply.started":"2024-05-14T19:36:20.476801Z","shell.execute_reply":"2024-05-14T19:36:20.476820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_tensor[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:36:20.477975Z","iopub.status.idle":"2024-05-14T19:36:20.478914Z","shell.execute_reply.started":"2024-05-14T19:36:20.478707Z","shell.execute_reply":"2024-05-14T19:36:20.478726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = TensorDataset(input_tensor, target_tensor)\n\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\n\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)  # Don't shuffle validation data","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:36:20.480442Z","iopub.status.idle":"2024-05-14T19:36:20.480872Z","shell.execute_reply.started":"2024-05-14T19:36:20.480679Z","shell.execute_reply":"2024-05-14T19:36:20.480695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_batches(loader, name):\n    n_batches = 0\n    for i in loader:\n        n_batches+=1\n\n    print(f\"Number of batches in {name}: \",n_batches)\n\ncount_batches(train_loader, \"train_loader\")\ncount_batches(val_loader, \"val_loader\")","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:36:20.482344Z","iopub.status.idle":"2024-05-14T19:36:20.482736Z","shell.execute_reply.started":"2024-05-14T19:36:20.482549Z","shell.execute_reply":"2024-05-14T19:36:20.482564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pad_token","metadata":{"id":"ae6bi9LpuaQW","outputId":"61b8a90d-6550-4171-934e-058f893618cf","execution":{"iopub.status.busy":"2024-05-14T19:36:20.484912Z","iopub.status.idle":"2024-05-14T19:36:20.485328Z","shell.execute_reply.started":"2024-05-14T19:36:20.485139Z","shell.execute_reply":"2024-05-14T19:36:20.485155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class WordEmbedder(nn.Module):\n    def __init__(self, vocab_size, embedding_dim):\n        super().__init__()\n        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n\n    def forward(self, x):\n        return self.embeddings(x)","metadata":{"id":"3cc71826-b2db-4607-96cb-fdb8fe327305","execution":{"iopub.status.busy":"2024-05-14T19:36:20.486854Z","iopub.status.idle":"2024-05-14T19:36:20.487492Z","shell.execute_reply.started":"2024-05-14T19:36:20.487289Z","shell.execute_reply":"2024-05-14T19:36:20.487307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now that we have successfully trained our word embedding layer, time to make our positional matrix, which we will make using the formula mentioned in the paper\ndef positional_encoding(seq_len, embedding_dim, device=device):\n        positional_encoding = torch.zeros(seq_len, embedding_dim)\n        position = torch.arange(0, seq_len, dtype=torch.float32).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, embedding_dim, 2).float() * (-torch.log(torch.tensor(10000.0)) / embedding_dim))\n        positional_encoding[:, 0::2] = torch.sin(position * div_term)\n        positional_encoding[:, 1::2] = torch.cos(position * div_term)\n        return positional_encoding","metadata":{"id":"97ec5fef-72c5-4524-b4b2-2c3df5905682","execution":{"iopub.status.busy":"2024-05-14T19:36:20.488865Z","iopub.status.idle":"2024-05-14T19:36:20.489574Z","shell.execute_reply.started":"2024-05-14T19:36:20.489361Z","shell.execute_reply":"2024-05-14T19:36:20.489379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positional_encoding(seq_len, embedding_dim).unsqueeze(0).expand(batch_size, -1, -1).shape","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:36:20.491387Z","iopub.status.idle":"2024-05-14T19:36:20.491805Z","shell.execute_reply.started":"2024-05-14T19:36:20.491607Z","shell.execute_reply":"2024-05-14T19:36:20.491624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Time to make the Multi-head Self Attention block\nclass MultiHeadSelfAttention(nn.Module):\n    def __init__(self, heads, embedding_dim):\n        super(MultiHeadSelfAttention, self).__init__()\n        self.heads = heads\n\n        # 3 Linear Layers for Q, K and V\n        self.w_q = nn.Linear(embedding_dim, embedding_dim)\n        self.w_k = nn.Linear(embedding_dim, embedding_dim)\n        self.w_v = nn.Linear(embedding_dim, embedding_dim)\n\n        # Since the feature or embedding dimension is typically the last dimension\n        self.softmax = nn.Softmax(dim=-1)\n\n        # Last Linear layer for the attention\n        self.w_a = nn.Linear(embedding_dim, embedding_dim)\n\n    def forward(self, embedding_vector):\n        batch_size, seq_len, embedding_dim = embedding_vector.size()\n        # Compute Q, K, and V\n        Q = self.w_q(embedding_vector)\n        K = self.w_k(embedding_vector)\n        V = self.w_v(embedding_vector)\n\n        # Seperate into heads\n        head_dim = embedding_dim // self.heads\n        Q = Q.view(batch_size, self.heads, seq_len, head_dim)\n        K = K.view(batch_size, self.heads, seq_len, head_dim)\n        V = V.view(batch_size, self.heads, seq_len, head_dim)\n\n        # Calculate attention\n        attention = torch.matmul(self.softmax(torch.matmul(Q, K.transpose(-1, -2)) / torch.sqrt(torch.tensor(embedding_dim))), V).to(device)\n\n        # Concatenating the attention heads (Transposing for correct concatenation)\n        attention = attention.transpose(1, 2).reshape(batch_size, seq_len, embedding_dim)\n        output = self.w_a(attention)\n        # print(\"Shape after attention:\", output.shape)\n        # num_active_elements = torch.gt(output, -1).sum().item()\n        # total_elements = output.numel()\n        # print(f\"active  att: {num_active_elements}/{total_elements}\")\n        return output","metadata":{"id":"eb6f80c9-fd5a-4014-8750-3724b592e8fd","execution":{"iopub.status.busy":"2024-05-14T19:36:20.493137Z","iopub.status.idle":"2024-05-14T19:36:20.493916Z","shell.execute_reply.started":"2024-05-14T19:36:20.493706Z","shell.execute_reply":"2024-05-14T19:36:20.493724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Time to make the Masked Multi-head Self Attention block\nclass MaskedMultiHeadSelfAttention(nn.Module):\n    def __init__(self, heads, embedding_dim):\n        super(MaskedMultiHeadSelfAttention, self).__init__()\n        self.heads = heads\n\n        # 3 Linear Layers for Q, K and V\n        self.w_q = nn.Linear(embedding_dim, embedding_dim)\n        self.w_k = nn.Linear(embedding_dim, embedding_dim)\n        self.w_v = nn.Linear(embedding_dim, embedding_dim)\n\n        # Since the feature or embedding dimension is typically the last dimension\n        self.softmax = nn.Softmax(dim=-1)\n\n        # Last Linear layer for the attention\n        self.w_a = nn.Linear(embedding_dim, embedding_dim)\n\n    def forward(self, embedding_vector):\n        batch_size, seq_len, embedding_dim = embedding_vector.size()\n        # Compute Q, K, and V\n        Q = self.w_q(embedding_vector)\n        K = self.w_k(embedding_vector)\n        V = self.w_v(embedding_vector)\n\n        # Seperate into heads\n        head_dim = embedding_dim // self.heads\n        Q = Q.view(batch_size, self.heads, seq_len, head_dim)\n        K = K.view(batch_size, self.heads, seq_len, head_dim)\n        V = V.view(batch_size, self.heads, seq_len, head_dim)\n\n        # Create a mask for masking the attention score\n        mask = torch.triu(torch.ones(seq_len, seq_len, dtype=torch.bool), diagonal=1).unsqueeze(0).unsqueeze(0).expand(batch_size, self.heads, -1, -1).to(device)\n        value_to_fill = float('-inf')\n\n        # Calculate attention (including mask)\n        attention = torch.matmul(self.softmax(torch.matmul(Q, K.transpose(-1, -2)).masked_fill(mask, value_to_fill) / torch.sqrt(torch.tensor(embedding_dim))), V)\n        # Concatenating the attention heads (Transposing for correct concatenation)\n        attention = attention.transpose(1, 2).reshape(batch_size, seq_len, embedding_dim)\n        output = self.w_a(attention)\n        # print(\"Shape after mask:\", output.shape)\n        # num_active_elements = torch.gt(output, -1).sum().item()\n        # total_elements = output.numel()\n        # print(f\"active masked: {num_active_elements}/{total_elements}\")\n        return output","metadata":{"id":"6e0155ef-eee5-41c3-8c1b-48d9f40dc0ee","execution":{"iopub.status.busy":"2024-05-14T19:36:20.495968Z","iopub.status.idle":"2024-05-14T19:36:20.496591Z","shell.execute_reply.started":"2024-05-14T19:36:20.496343Z","shell.execute_reply":"2024-05-14T19:36:20.496363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = torch.triu(torch.ones(4, 4, dtype=torch.bool), diagonal=1).unsqueeze(0).unsqueeze(0).expand(2, 2, -1, -1)\nx","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:36:20.498179Z","iopub.status.idle":"2024-05-14T19:36:20.498609Z","shell.execute_reply.started":"2024-05-14T19:36:20.498402Z","shell.execute_reply":"2024-05-14T19:36:20.498418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.zeros(4, 4).masked_fill(x, float('-inf'))","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:36:20.499939Z","iopub.status.idle":"2024-05-14T19:36:20.500382Z","shell.execute_reply.started":"2024-05-14T19:36:20.500187Z","shell.execute_reply":"2024-05-14T19:36:20.500204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AddNorm(nn.Module):\n    def __init__(self, n_features):\n        super(AddNorm, self).__init__()\n        # Layer Norm will normalize the last dimension of the matrix\n        self.norm = nn.LayerNorm(n_features)\n\n    def forward(self, original, modified):\n        return self.norm(original + modified)","metadata":{"id":"c54ecdfc-9f1c-4120-8578-46e05d1c2069","execution":{"iopub.status.busy":"2024-05-14T19:36:20.502420Z","iopub.status.idle":"2024-05-14T19:36:20.503172Z","shell.execute_reply.started":"2024-05-14T19:36:20.502878Z","shell.execute_reply":"2024-05-14T19:36:20.502906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FeedForward(nn.Module):\n    def __init__(self, embedding_dim):\n        super(FeedForward, self).__init__()\n        # Normally nn.Linear(embedding_dim, embedding_dim * 4) for expressiveness, we will change it if we have the resources to do so\n        self.lr1 = nn.Linear(embedding_dim, embedding_dim)\n        self.relu = nn.ReLU()\n        self.lr2 = nn.Linear(embedding_dim, embedding_dim)\n\n    def forward(self, x):\n        x = self.lr1(x)\n        x = self.relu(x)\n        x = self.lr2(x)\n        # num_active_elements = torch.gt(x, -1).sum().item()\n        # total_elements = x.numel()\n        # print(f\"active feedforward: {num_active_elements}/{total_elements}\")\n        return x","metadata":{"id":"a1a5b4a5-96f7-40ba-9193-ab6e0dd7ccfc","execution":{"iopub.status.busy":"2024-05-14T19:36:20.504692Z","iopub.status.idle":"2024-05-14T19:36:20.505217Z","shell.execute_reply.started":"2024-05-14T19:36:20.504958Z","shell.execute_reply":"2024-05-14T19:36:20.504976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Time to build the Decoder\nclass Decoder(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, batch_size, seq_len, heads):\n        super(Decoder, self).__init__()\n        self.word_embedder = WordEmbedder(vocab_size, embedding_dim)\n        self.masked_attention = MaskedMultiHeadSelfAttention(heads, embedding_dim)\n        self.add_norm1 = AddNorm(embedding_dim)\n        self.attention = MultiHeadSelfAttention(heads, embedding_dim)\n        self.add_norm2 = AddNorm(embedding_dim)\n        self.feed_forward = FeedForward(embedding_dim)\n        self.add_norm3 = AddNorm(embedding_dim)\n        self.linear = nn.Linear(embedding_dim, vocab_size)\n\n    def forward(self, x):\n        # print(\"Shape before word embedder:\", x.shape)\n        x = self.word_embedder(x)\n        # print(\"Shape after word embedder/before positional:\", x.shape)\n        # num_active_elements = torch.gt(x, -1).sum().item()\n        # total_elements = x.numel()\n        # print(f\"active word embedder: {num_active_elements}/{total_elements}\")\n        x += positional_encoding(x.shape[1], x.shape[2]).unsqueeze(0).expand(x.shape[0], x.shape[1], x.shape[2]).to(device)\n        # print(\"Shape after positional:\", x.shape)\n        # num_active_elements = torch.gt(x, -1).sum().item()\n        # total_elements = x.numel()\n        # print(f\"active positional_encoding: {num_active_elements}/{total_elements}\")\n#         print(x.shape)\n        x = self.add_norm1(x, self.masked_attention(x))\n        # print(\"Shape after addnorm1:\", x.shape)\n        # num_active_elements = torch.gt(x, -1).sum().item()\n        # total_elements = x.numel()\n        # print(f\"active add_norm1: {num_active_elements}/{total_elements}\")\n#         print(x.shape)\n        x = self.add_norm2(x, self.attention(x))\n        # print(\"Shape after addnorm2:\", x.shape)\n        # num_active_elements = torch.gt(x, -1).sum().item()\n        # total_elements = x.numel()\n        # print(f\"active add_nor2: {num_active_elements}/{total_elements}\")\n#         print(x.shape)\n        x = self.add_norm3(x, self.feed_forward(x))\n        # print(\"Shape after addnorm3:\", x.shape)\n        # num_active_elements = torch.gt(x, -1).sum().item()\n        # total_elements = x.numel()\n        # print(f\"active add_norm3: {num_active_elements}/{total_elements}\")\n#         print(x.shape)\n        # print(\"Shape before linear:\", x.shape)\n        logits = self.linear(x)\n        # print(\"Shape after linear:\", logits.shape)\n        # num_active_elements = torch.gt(logits, 0).sum().item()\n        # total_elements = logits.numel()\n        # print(f\"active linear: {num_active_elements}/{total_elements}\")\n        return logits","metadata":{"id":"9fe1f5ed-35ce-479b-b596-d2cc95a2c06c","execution":{"iopub.status.busy":"2024-05-14T19:36:20.507425Z","iopub.status.idle":"2024-05-14T19:36:20.507811Z","shell.execute_reply.started":"2024-05-14T19:36:20.507626Z","shell.execute_reply":"2024-05-14T19:36:20.507641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Decoder(vocab_size, embedding_dim, batch_size, seq_len, heads).to(device)\nmodel","metadata":{"id":"881cd445-c7fb-4f2b-ae1f-d6807b2f76a5","execution":{"iopub.status.busy":"2024-05-14T19:36:20.508985Z","iopub.status.idle":"2024-05-14T19:36:20.510202Z","shell.execute_reply.started":"2024-05-14T19:36:20.509959Z","shell.execute_reply":"2024-05-14T19:36:20.509979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize our optimizer and loss function\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nloss_fn = nn.CrossEntropyLoss(ignore_index=pad_token)","metadata":{"id":"3026a026-a1e7-4f12-9f82-8a78982bb1ed","execution":{"iopub.status.busy":"2024-05-14T19:36:20.511655Z","iopub.status.idle":"2024-05-14T19:36:20.512075Z","shell.execute_reply.started":"2024-05-14T19:36:20.511859Z","shell.execute_reply":"2024-05-14T19:36:20.511875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_poem(model, start_sequence, tokenizer=sp, max_length=300):\n    model.eval()\n    tokens = sp.encode_as_ids(start_sequence)\n    generated_ids = [sp.piece_to_id(\"<s>\")] + tokens\n    input_seq = torch.tensor([generated_ids], dtype=torch.long).to(device)\n\n    for _ in range(max_length):\n        with torch.no_grad():\n            logits = model(input_seq)\n            logits = logits[:, -1, :]\n            probs = F.softmax(logits, dim=-1)\n            idx_next = torch.multinomial(probs, num_samples=1)\n            next_token_id = idx_next.item()\n\n            # Append the newly generated token to the input sequence\n            input_seq = torch.cat([input_seq, torch.tensor([next_token_id], dtype=torch.long).unsqueeze(0).to(device)], dim=1)\n            generated_ids.append(next_token_id)\n\n            if next_token_id == sp.piece_to_id(\"</s>\"):\n                break\n\n    generated_text = sp.decode_ids(generated_ids)\n    return generated_text","metadata":{"id":"5132ae30-6205-4e12-a54e-b58b3f03e1bf","execution":{"iopub.status.busy":"2024-05-14T19:36:20.513124Z","iopub.status.idle":"2024-05-14T19:36:20.513510Z","shell.execute_reply.started":"2024-05-14T19:36:20.513316Z","shell.execute_reply":"2024-05-14T19:36:20.513331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_epoch(data_loader, model, optimizer, loss_fn, device, pad_token):\n    model.train()\n    total_loss = 0.0\n\n    # Wrap your data loader with tqdm for a progress bar\n    progress_bar = tqdm(train_loader, desc=\"Training\", leave=True)\n\n    for input_batch, target_batch in progress_bar:\n        input_data = input_batch.to(device)\n        target_data = target_batch.to(device)\n        optimizer.zero_grad()\n\n        # Forward pass\n        probs = model(input_data)\n\n        # Reshape input and output to correct format for loss calculation\n        B, T, C = probs.shape\n        probs = probs.view(B * T, C)\n        target_data = target_data.view(-1)\n\n        # Calculate loss\n        loss = loss_fn(probs, target_data)\n\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n        # Update the progress bar with the current batch loss\n        progress_bar.set_postfix(loss=loss.item())\n\n    return total_loss / len(data_loader)  # Average loss\n\ndef validate_epoch(data_loader, model, loss_fn, device, pad_token):\n    model.eval()\n    total_loss = 0.0\n\n    with torch.no_grad():\n    # Wrap your data loader with tqdm for a progress bar\n        progress_bar = tqdm(val_loader, desc=\"Validation\", leave=True)\n\n        for input_batch, target_batch in progress_bar:\n            input_data = input_batch.to(device)\n            target_data = target_batch.to(device)\n\n            # Forward pass\n            probs = model(input_data)\n\n            # Reshape input and output to correct format for loss calculation\n            B, T, C = probs.shape\n            probs = probs.view(B * T, C)\n            target_data = target_data.view(-1)\n\n            # Calculate loss\n            loss = loss_fn(probs, target_data)\n\n            total_loss += loss.item()\n\n            # Update the progress bar with the current batch loss (optional)\n            # progress_bar.set_postfix(loss=loss.item())\n\n        return total_loss / len(data_loader)  # Average loss\n\nepoch_losses = []\nvalidation_losses = []\n\nfor epoch in range(epochs):\n    print(f\"Starting Epoch {epoch + 1}/{epochs}\")\n    train_loss = train_epoch(train_loader, model, optimizer, loss_fn, device, pad_token)\n    val_loss = validate_epoch(val_loader, model, loss_fn, device, pad_token)\n    epoch_losses.append(train_loss)\n    validation_losses.append(val_loss)\n    print(f\"Epoch {epoch + 1}, Train Loss: {train_loss:.15f}, Validation Loss: {val_loss:.15f}\")\n    print(generate_poem(model, \"flower\"))","metadata":{"id":"bbfdc8bd-74e2-45f3-87ea-03c882aa2dee","outputId":"dd835b43-6df6-4fe5-dfbe-1c87dddc1634","execution":{"iopub.status.busy":"2024-05-14T19:36:20.514728Z","iopub.status.idle":"2024-05-14T19:36:20.515114Z","shell.execute_reply.started":"2024-05-14T19:36:20.514916Z","shell.execute_reply":"2024-05-14T19:36:20.514931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:36:20.516749Z","iopub.status.idle":"2024-05-14T19:36:20.517661Z","shell.execute_reply.started":"2024-05-14T19:36:20.517283Z","shell.execute_reply":"2024-05-14T19:36:20.517342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x.shape[0], x.shape[1], x.shape[2])","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:36:20.519658Z","iopub.status.idle":"2024-05-14T19:36:20.520226Z","shell.execute_reply.started":"2024-05-14T19:36:20.519929Z","shell.execute_reply":"2024-05-14T19:36:20.519950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(1, epochs + 1), epoch_losses, validation_losses) \nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Training Loss\")\nplt.title(\"Training Loss Over Epochs\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:36:20.524354Z","iopub.status.idle":"2024-05-14T19:36:20.524794Z","shell.execute_reply.started":"2024-05-14T19:36:20.524596Z","shell.execute_reply":"2024-05-14T19:36:20.524613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(epochs-5), epoch_losses[5:], label='Training Loss')\nplt.plot(range(epochs-5), validation_losses[5:], label='Validation Loss')\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Training Loss\")\nplt.title(\"Training Loss Over Epochs\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:36:20.525985Z","iopub.status.idle":"2024-05-14T19:36:20.526439Z","shell.execute_reply.started":"2024-05-14T19:36:20.526239Z","shell.execute_reply":"2024-05-14T19:36:20.526256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = \"model_weights.pth\"\ntorch.save(model.state_dict(), model_path)","metadata":{"id":"04YLCbmquaQY","execution":{"iopub.status.busy":"2024-05-14T19:36:20.527455Z","iopub.status.idle":"2024-05-14T19:36:20.528372Z","shell.execute_reply.started":"2024-05-14T19:36:20.528083Z","shell.execute_reply":"2024-05-14T19:36:20.528114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"model_weights.pth\"))\nmodel.eval()","metadata":{"id":"dJ30__kSuaQY","outputId":"c6f8f46e-d6bb-4a37-9ea3-0e70e0b6cb1b","execution":{"iopub.status.busy":"2024-05-14T19:36:20.530115Z","iopub.status.idle":"2024-05-14T19:36:20.530531Z","shell.execute_reply.started":"2024-05-14T19:36:20.530334Z","shell.execute_reply":"2024-05-14T19:36:20.530350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_sequence = \"flower\"\npoem = generate_poem(model, start_sequence)\nprint(poem)","metadata":{"id":"01b5e8f6-5146-4019-9f45-08c003279b49","outputId":"b75d8021-cc0c-464e-a6e6-740b75d1c445","execution":{"iopub.status.busy":"2024-05-14T19:36:20.531967Z","iopub.status.idle":"2024-05-14T19:36:20.532414Z","shell.execute_reply.started":"2024-05-14T19:36:20.532217Z","shell.execute_reply":"2024-05-14T19:36:20.532234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"23f509d4-499c-4267-928b-b0379cde2b36"},"execution_count":null,"outputs":[]}]}